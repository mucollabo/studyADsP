data.frame(v1, v2, v3)
v1 <- c(10, 20, 30);
names(v1) <- c("Moe", "Larry", "Curly")
v1["Larry"]
v2 <- c(10, 20, 30);
v3 <- c(10, 20, 30);
data.frame(v1, v2, v3)
names(v2) <- c("Charles", "Ahn", "Kim")
data.frame(v1, v2, v3)
new <- data.frame(a=1, b=2, c=3, d="a")
new1 <- data.frame(a=1, b=2, c=3, d="a")
rbind(new, new1)
cbind(new, new1)
newRdata <- rbind(new, new1)
newRdata
print(newRdata)
newcol = 1:150
cbind(newRdata, newcol)
newRdata[newRdata$c=3]
newRdata[newRdata$c="3"]
newRdata[newRdata$c=="3"]
newRdata[newRdata$c==3]
subset(newRdata, select = b, subset = b>1)
subset(newRdata, select = b, subset = b>2)
subset(newRdata, select = b, subset = b>=2)
newRdata[[2]]
newRdata[2]
newRdata[2,]
newRdata[, 2]
newRdata[["Charles"]]
v1
v2
v3
newDF <- data.frame(v1, v2)
newDF
newDF[["Charles"]]
newDF[["Larry"]]
newDF["Charles"]
newDF[,"Larry"]
newDF[[v1]]
newDF$Charles
newDF$Larry
newDF$v1
newDF[v1]
colnames(newDF)
rownames(newDF)
colnames(newDF) <- first
colnames(newDF) <- "first"
newDF
colnames(newDF) <- "first", "second"
colnames(newDF) <- ["first", "second"]
colnames(newDF) <- [first, second]
colnames(newDF.NA) <- "second"
subset(newDF, select=-"NA")
subset(newDF, select=-"first")
subset(newDF, select=-NA)
subset(newDF, select=-first)
newDF
as.vector(newDF)
as.list(newDF)
as.matrix(newDF)
a<-2
sapply(a, log)
a<-1
sapply(a, log)
newRdata
write.csv(newRdata, "newRdata.csv")
save(newRdata, file = "newRdata.Rdata")
read.csv("newRdata.csv")
load("newRdata.R")
load("newRdata.Rdata")
View(newRdata)
View(newDF)
View(new1)
View(new)
rm(newDF)
data()
data(AirPassengers)
force(AirPassengers)
data(BOD)
force(BOD)
View(BOD)
summary(AirPassengers)
summary(BOD)
head(AirPassengers)
head(BOD)
library(MASS)
MASS
sp<-split(Cars93$MPG.city, Cars93$Origin)
View(sp)
View(sp)
median(sp[[1]])
nchar("charles")
length("charles")
length(a)
nchar(a)
nchar(v1)
length(v1)
paste("charles", "dev", sep = "-")
paste("the pi is approximately", pi)
paste(vec, "loves me", collapse = ",and")
name <- "Charles"
paste(vec, "loves me", collapse = ",and")
paste(name, "loves me", collapse = ",and")
name <- ["Charles", "Ahn"]
name <- c("Charles", "Ahn")
paste(name, "loves me", collapse = ",and")
paste(name, "loves me", collapse = ",and ")
paste(name, "loves me", collapse = " ,and ")
paste(name, "loves me", collapse = ", and ")
substr("statistics", 1, 4)
strsplit("the pi is approximately", " ")
sentance <- "the pi is approximately"
sub(pi, log, string)
sub(sentance, pi, log)
sub(sentance, "pi", "log")
sentance
sentance <- sub(sentance, "pi", "log")
sentance
sentance <- "the pi is approximately"
sentance
Sys.Date()
as.Date()
today <- as.Date()
today <- Sys.Date()
as.Date(today)
format(Sys.Date(), '%a')
format(Sys.Date(), '%b')
format(Sys.Date(), '%B')
format(Sys.Date(), '%d')
format(Sys.Date(), '%m')
format(Sys.Date(), '%y')
format(Sys.Date(), '%Y')
d <- as.Date("2014-12-25")
d
p <- as.POSIXlt(d)
p
p$yday
start <- as.Date("2014-12-01")
end <- as.Date("2014-12-25")
seq(from=start, to=end, by=1)
data(mtcars)
a <- mtcars$mpg
b <- mtcars$hp
cor(a,b)
cov(a,b)
cor.test(a, b, method = "pearson")
x <- c(19,23,26,29,30,38,39,46,49)
y <- c(33,51,40,49,50,69,70,64,89)
lm(y~x)
summary(lm(y~x))
library(MASS)
head(Cars93)
attach(Cars93)
lm(Price~EngineSize+RPM+Weight, data = Cars93)
summary(lm(Price~EngineSize+RPM+Weight, data = Cars93))
head(Cars93, 10)
Cars93
library(boot)
data(nodal)
boot
nodal
a <- c(2,4,6,7)
data <- nodal[,a]
glmModel <- glm(r~., data = data, family = "binomial")
summary(glmModel)
x1 <- c(7, 1, 11, 11, 7, 11, 3, 1, 2, 21, 1, 11, 10)
x2 <- c(26, 29, 56, 31, 52, 55, 71, 31, 54, 47, 40, 66, 68)
x3 <- c(6, 15, 8, 8, 6, 9, 17, 22, 18, 4, 24, 9, 8)
x4 <- c(60, 52, 20, 47, 33, 22, 6, 44, 22, 26, 34, 12, 12)
y <- c(78.5, 74.3, 104.3, 87.6, 95.9, 109.2, 102.7, 72.5, 93.1, 115.9, 83.8, 113.3, 109.4)
df <- data.frame(x1, x2, x3, x4, y)
head(df)
# create regression
a <- lm(y ~ x1 + x2 + x3 + x4, data = df)
summary(a)
head(df, 13)
a
summary(a)
b <- lm(y ~ x1 + x2 + x3, data = df)
summary(b)
c <- lm(y ~ x1 + x2, data = df)
summary(c)
# apply forward selection with step method
step(lm(y~1, data = df), scope = list(lower=~1, upper=~x1+x2+x3+x4), direction = "forward")
# apply backward elimination
library(ElemStatLearn)
library()
data()
install.packages("ElemStatLearn")
library(tseries)
install.packages("tseries")
library(tseries)
library(forecast)
install.packages("forecast")
library(forecast)
library(TTR)
king <- scan("http://robjhyndman.com/tsdldata/misc/kings.dat", skip = 3)
king.ts <- ts(king)
plot.ts(king.ts)
king.sma3 <- SMA(king.ts, n=3)
plot.ts(king.sma3)
king.sma8 <- SMA(king.ts, n=8)
plot.ts(king.sma8)
king.ff1 <- diff(king.ts, differences = 1)
plot.ts(king.ff1)
acf(king.ff1, lag.max = 20)
acf(king.ff1, lag.max = 20, plot = FALSE)
pacf(king.ff1, lag.max = 20)
pacf(king.ff1, lag.max = 20, plot = FALSE)
auto.arima(king)
king.arima <- arima(king, order = c(0, 1, 1))
king.forecats <- forecast(king.arima)
king.forecasts <- forecast(king.arima)
rm forecasts
remove(forecasts)
remove forecats
View(king.forecats)
rm(forecats)
rm(king.forecats)
king.forecasts
king.forecasts <- forecast(king.arima, h=5)
king.forecasts
library(MASS)
loc <- cmdscale(eurodist)
x <- loc[, 1]
y <- loc[, 2]
y <- -loc[, 2]
eurodist
plot(x, y, type = "n", asp = 1, main = "Metric MDS")
text(x, y, rownames(loc), cex=0.7)
abline(v=0, h=0, lty=2, lwd=0.5)
data(swiss)
swiss.x <- as.matrix(swiss[, -1])
swiss.dist <- dist(swiss.x)
swiss.mds <- isoMDS(swiss.dist)
plot(swiss.mds$points, type = "n")
text(swiss.mds$points, labels = as.character(1:nrow(swiss.x)))
abline(v=0, h=0, lty=2, lwd=0.5)
swiss.x <- as.matrix(swiss[, -1])
swiss.sammon <- sammon(dist(swiss.x))
plot(swiss.sammon$points, type = "n")
text(swiss.sammon$points, labels = as.character(1:nrow(swiss.x)))
abline(v=0, h=0, lty=2, lwd=0.5)
datasets
library(datasets)
data(USArrests)
pairs(USArrests, panel = panel.smooth, main = "USArrests data")
US.prin <- princomp(USArrests, cor = TRUE)
summary(US.prin)
loadings(US.prin)
US.prin$scores
arrests.pca <- prcomp(USArrests, center = TRUE, scale. = TRUE)
biplot(arrests.pca, scale = 0)
library(rpart)
library(party)
install.packages("party")
library(party)
library(ROCR)
install.packages("ROCR")
library(ROCR)
x <- kyphosis[sample(1:nrow(kyphosis), nrow(kyphosis), replace = F),]
x.train <- kyphosis[1:floor(nrow(x)*0.75),]
x.evaluate <- kyphosis[floor(nrow(x)*0.75):nrow(x),]
x.model <- cforest(Kyphosis~Age+Number+Start, data = x.train)
x.evaluate$prediction <- predict(x.model, newdata=x.evaluate)
x.evaluate$correct <- x.evaluate$prediction == x.evaluate$Kyphosis
print(paste("% of predicted classsification correct", mean(x.evaluate$correct)))
x.evaluate$probabilities <- 1 - unlist(treeresponse(x.model, newdata=x.evaluate), use.names = F)[seq(1, nrow(x.evaluate)*2, 2)]
pred <- prediction(x.evaluate$probabilities, x.evaluate$Kyphosis)
perf <- performance(pred, "tpr", "fpr")
plot(perf, main="ROC curve", colorize=T)
perf <- performance(pred, "lift", "rpp")
plot(perf, main="lift curve", colorize=T)
a <- iris[iris$Species=="setosa" | iris$Species=="versicolor",]
b <- glm(Species ~ Sepal.Length, data=a, family=binomial)
summary(b)
idx <- sample(2, nrow(iris), replace = TRUE, prob = c(0.7, 0.3))
train.data <- iris[idx==1,]
test.data <- iris[idx==2,]
# create model with train.data
iris.tree <- ctree(Species~., data=train.data)
plot(iris.tree)
plot(iris.tree, type="simple")
# compare predict data and real data
table(predict(iris.tree), train.data$Species)
# validation with test data
test.pre <- predict(iris.tree, newdata=test.data)
table(test.pre, test.data$Species)
